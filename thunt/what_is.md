# What Is Threat Hunting?

## Defining Threat Hunting

Threat hunting is the proactive and iterative search through networks, endpoints, and datasets to detect malicious, suspicious, or risky activities that have evaded existing security solutions. Unlike traditional security operations that react to alerts generated by automated systems, threat hunting operates on the assumption that adversaries are already present in the environment and seeks to discover them through human-led investigation and analysis.

At its core, threat hunting represents a fundamental shift in defensive strategy. Traditional security models operate on a detection-response paradigm:
- Deploy controls,
- Wait for alerts, Investigate alerts,
- Respond to confirmed incidents.

Threat hunting inverts this model by beginning with a hypothesis or question and actively searching for evidence of compromise before automated systems generate alerts - or in cases where automated systems may never generate alerts at all.

The SANS Institute provides a concise definition that captures this essence: **"Threat hunting is the process of proactively and iteratively searching through networks to detect and isolate advanced threats that evade existing security solutions."** This definition emphasizes three critical characteristics:

- **Proactive**: Hunters initiate investigations rather than waiting for alerts
- **Iterative**: Hunting is a continuous process, not a one-time exercise
- **Focused on evasion**: Hunting targets threats specifically designed to bypass automated defenses

## The Reactive-Proactive Spectrum

To understand where threat hunting sits within the broader security ecosystem, it's helpful to visualize security activities along a reactive-proactive spectrum:

```
REACTIVE ←―――――――――――――――――――――――――――――――――――→ PROACTIVE

Incident         Alert            Scheduled         Hypothesis-Driven
Response         Triage           Hunting           Hunting
    ↓               ↓                 ↓                  ↓
Responding    Investigating    Routine checks    Creative
to confirmed  automated        based on          investigation
incidents     alerts           patterns          based on TTPs

			                        ← Threat Hunting →
```

Traditional SOC operations occupy the left side of this spectrum, primarily responding to events that security tools have already identified. Threat hunting occupies the right side, initiating investigations based on hypotheses, curiosity, or intelligence about adversary behavior - often before any automated system has detected suspicious activity.

This doesn't mean threat hunting replaces reactive security operations. Rather, both are essential components of defense-in-depth. Automated detection handles known threats at scale, while threat hunting discovers unknown threats through human creativity and analysis.

## Core Characteristics of Threat Hunting

### 1. Hypothesis-Driven Investigation

Threat hunting typically begins with a hypothesis - an educated guess about how an adversary might compromise or move through your environment. These hypotheses are informed by:

- Threat intelligence about active adversary campaigns
- Understanding of MITRE ATT&CK techniques relevant to your environment
- Knowledge of organizational vulnerabilities and high-value assets
- Previous incidents or near-misses
- Anomalies observed in baseline behaviour (Behavioural Analysis)

For example: "If an adversary compromised a user workstation, they might attempt to enumerate domain administrators using built-in Windows utilities like 'net group' or PowerShell cmdlets. Let me search our endpoint logs for processes executing these commands from non-administrative users."

Another example informed by behavioural insights: "The way this specific process is periodically communicating outbound over an unusual port to an unknown host is reminiscent of C2 communication. Let me look at the communication closer using RITA and Zeek to see what else I can learn about the nature of the communication."

### 2. Focused on Unknown Threats

While automated systems excel at detecting known threat patterns, threat hunting explicitly targets the threats that slip through the cracks. Consider the modern security environment: your antivirus catches known malware signatures, your firewall blocks suspicious IP addresses, and your SIEM alerts on predefined correlation rules. But what about the zero-day exploit that has no signature yet? What about the adversary who uses PowerShell, WMI, and other legitimate administrative tools - techniques often called "living off the land" - to avoid deploying any malicious binaries that could be detected?

These are the threats that keep security leaders awake at night. An insider with legitimate credentials behaving maliciously doesn't trigger authentication alerts because they're using valid credentials. An advanced persistent threat group conducting slow, methodical reconnaissance over weeks or months stays beneath the velocity thresholds that would trigger behavioral analytics. A sophisticated adversary using custom-developed malware specifically designed to evade your security stack won't match any known indicators of compromise.

The fundamental assumption underlying all threat hunting is both sobering and pragmatic: some threats will inevitably bypass automated defenses. As SANS instructor Rob Lee memorably puts it, signature-based detection looks for "deer," but adversaries can evade detection by simply adding a "moustache" - making trivial modifications to their tactics, techniques, and procedures that render signatures ineffective.

Change a few bytes in malware, alter command-line parameters, or use a different file extension, and suddenly the "deer" your defences were trained to recognize becomes unrecognizable. Automated systems can't broaden their detection criteria to catch these variations because doing so would generate unacceptable false positive rates and potentially degrade system performance - the cure would be worse than the disease.

This is where human threat hunters provide irreplaceable value. While machines fail to recognize the deer once the moustache is added, humans excel at pattern recognition within broader contextual frameworks. A skilled analyst can look at the evidence and think, "that's a deer wearing a moustache" - recognizing the fundamental nature of the threat despite superficial modifications.

No signature database is complete, no behavioural baseline is perfect, and adversaries continuously adapt their techniques specifically to evade detection. Human investigation becomes the essential complementary capability - bringing creativity, context, and the ability to recognize patterns that no rule anticipated, whether the deer has a moustache or not.



### 3. Iterative and Continuous

```
                    ╔═══════════════════════════════════════╗
                    ║   CONTINUOUS THREAT HUNTING CYCLE     ║
                    ╚═══════════════════════════════════════╝
                                      │
                    ┌─────────────────┴─────────────────┐
                    │                                   │
            ┌───────▼────────┐                          │
            │   INITIATION   │                          │
            │                │                          │
            │  • Hypothesis  │                          │
            │  • Intel/Leads │                          │
            │  • Curiosity   │                          │
            │  • Behavioural │                          │
            └───────┬────────┘                          │
                    │                                   │
            ┌───────▼────────┐                          │
            │ INVESTIGATION  │                          │
            │                │                          │
            │  • Query Data  │                          │
            │  • Correlate   │                          │
            │  • Pivot/Adapt │                          │
            └───────┬────────┘                          │
                    │                                   │
            ┌───────▼────────┐                          │
            │   DISCOVERY    │                          │
            │                │                          │
            └───┬────────┬───┘                          │
                │        │                              │
     ┌──────────┘        └──────────┐                   │
     │                              │                   │
┌────▼─────┐                  ┌─────▼──────┐            │
│  THREAT  │                  │  NO THREAT │            │
│  FOUND   │                  │   FOUND    │            │
└────┬─────┘                  └─────┬──────┘            │
     │                              │                   │
┌────▼─────────┐              ┌─────▼──────────────┐    │
│   INCIDENT   │              │  VALIDATION/       │    │
│   RESPONSE   │              │  LEARNING          │    │
│              │              │                    │    │
│ • Contain    │              │ • Validate Defenses│    │
│ • Eradicate  │              │ • Improve Baseline │    │
│ • Recover    │              │ • Identify Gaps    │    │
└────┬─────────┘              └──────┬─────────────┘    │
     │                               │                  │
     └───────────┬───────────────────┘                  │
                 │                                      │
         ┌───────▼──────────┐                           │
         │  REFINEMENT      │                           │
         │                  │                           │
         │ • Document       │                           │
         │ • Create Rules   │                           │
         │ • New Hypothesis ├───────────────────────────┘
         └──────────────────┘
            (Cycle Repeats)
```


Threat hunting is not a project with a defined end date, it's an operational capability that runs continuously. Think of it as analogous to physical security: you don't patrol a facility once and declare it secure forever. Similarly, the threat landscape evolves, your environment changes, and new attack techniques emerge constantly, requiring ongoing vigilance.

What makes hunting truly powerful is that it creates a self-improving cycle. Each hunt - whether it finds threats or not - produces insights that make future hunts more effective. This cycle typically follows this pattern:

You begin by generating a hypothesis based on threat intelligence, knowledge of your environment, insight provided from routine behavioural analysis, or simple curiosity about potential attack vectors. This represents the **initiation phase**.

Next comes the **investigation phase**, where you query your data sources, analyze logs, and correlate events across different systems. You're searching for evidence that supports or refutes your hypothesis. This is where the hunter's skill really shines - knowing which data to examine, how to pivot when initial queries yield nothing, and how to distinguish signal from noise.

The **discovery phase** yields one of several outcomes. You might find an actual threat that requires immediate response. You might validate that your hypothesis was incorrect but learn something valuable about normal behavior in your environment. You might identify gaps in your logging or detection coverage that need to be addressed. Each outcome has value.

If you do **find threats**, you transition to **incident response** - containing, eradicating, and recovering from the incident. But even after the immediate threat is addressed, the hunting process continues with a **refinement phase**. You document what you found, work with detection engineers to create automated rules that will catch similar threats in the future, and use your new knowledge to generate hypotheses for the next hunt. This is where the relationship between Threat Hunting and Detection Engineering especially becomes crucial.

In a well-design Threat Hunting system even hunts that **find nothing produce organizational value**. They validate that your defences are functioning correctly, they improve hunters' mental models of the environment, they reveal areas where documentation or baselining could be improved, and they build the expertise that will make future hunts more efficient. A mature hunting program views these "null results" not as wasted effort but as important validation and learning opportunities.

### 4. Human-Led Analysis

While threat hunting leverages sophisticated tools and technologies extensively, it fundamentally depends on something that cannot be automated: human creativity, intuition, and contextual reasoning. This is not merely a philosophical preference - it's a practical necessity driven by the nature of the problem.

Consider what makes an effective threat hunter. They must think like an adversary, constantly asking "If I wanted to compromise this environment, how would I do it?" This adversarial mindset allows hunters to anticipate attack paths that haven't been explicitly documented or detected before. When investigating, they recognize subtle anomalies that automated systems miss because those systems can only alert on what they've been programmed to detect. A human hunter notices when something feels wrong - perhaps a pattern of behavior that's technically within normal parameters but contextually suspicious.

Context is perhaps the most critical element that humans bring to hunting. Automated systems lack the deep understanding of business operations, organizational politics, user relationships, and system architecture that experienced hunters accumulate. When you see a database administrator running unusual queries at 2 AM, is that malicious or is it emergency maintenance for tomorrow's product launch? When you observe large data transfers to a cloud storage service, is that data exfiltration or is the marketing team uploading assets for the new campaign? These questions require contextual knowledge that exists in human minds, not in rule engines.

Hunters must also be able to pivot their investigation directions based on preliminary findings. If an initial hypothesis proves unfruitful, they don't simply stop - they adjust their approach, follow tangential leads, and explore related questions. This dynamic, creative problem-solving process resists automation because it requires making judgment calls about which threads to pursue and which to abandon, often based on intuition developed through experience.

Finally, hunters must distinguish between genuinely malicious activity and the countless benign anomalies that occur in any complex environment. Organizations generate millions of security events daily, many of which are unusual but harmless. The human ability to apply judgment, weigh evidence, and make probabilistic assessments about threat likelihood is what prevents hunting from drowning in false positives.

This human element is what allows hunting to discover threats that are novel, well-hidden, or specifically designed to evade automated detection. It's the essential capability that complements automated systems: machines provide speed and scale for known threats, while humans provide insight and creativity for unknown threats.

## What Threat Hunting Is Not

To fully understand threat hunting, it's equally important to clarify what it is not:

**Not Incident Response**: Threat hunting occurs before an incident is confirmed. Once a threat is validated and containment begins, the activity transitions to incident response. Hunting is the search; incident response is the reaction.

**Not Vulnerability Management**: While hunters should be aware of vulnerabilities in their environment, hunting focuses on detecting active exploitation or presence of threats, not cataloging potential weaknesses.

**Not Penetration Testing or Red Teaming**: These activities simulate attacks to test defenses. Threat hunting assumes defenses have already been bypassed and searches for actual threats.

**Not Pure Automation**: Tools labeled as "automated threat hunting" are typically advanced anomaly detection or behavioural analytics systems. True hunting requires human hypothesis generation, creative investigation paths, and contextual judgment.

**Not Alert Triage**: Investigating alerts generated by SIEM, EDR, or IDS systems is standard SOC work. Hunting begins without an alert, driven by curiosity or hypothesis rather than system-generated notification.

## The Value Proposition

Organizations invest in threat hunting because it provides several critical capabilities:

### Reduced Dwell Time

Industry research consistently shows that adversaries remain undetected in victim networks for weeks or months (the "dwell time"). The 2023 Mandiant M-Trends report noted a global median dwell time of 16 days. Proactive hunting can dramatically reduce this window by discovering threats before they achieve their objectives.

### Discovery of Evasive Threats

Advanced adversaries specifically design their tools, techniques, and operational patterns to avoid detection. Threat hunting is often the only way to discover these sophisticated threats that are invisible to automated systems.

### Validation of Security Controls

Even hunts that find no threats provide value by validating that existing security controls are functioning correctly and that the environment matches expected baselines.

### Improved Detection Capabilities

Insights from hunting feed back into automated detection systems. When hunters discover a novel technique, detection engineers can create rules to catch it automatically in the future, raising the organization's overall security posture.

### Organizational Learning

Hunting develops deep expertise about the environment, threat landscape, and adversary behaviour. This knowledge improves all security functions, from architecture decisions to incident response effectiveness.

## Prerequisites for Effective Hunting

Not every organization is ready for threat hunting. Effective hunting requires certain foundational capabilities:

- **Adequate logging and visibility**: Can't hunt what you can't see
- **Centralized data access**: Hunters need efficient access to diverse data sources
- **Baseline understanding of normal**: Must know what's typical to identify what's anomalous
- **Skilled personnel**: Hunters need deep technical knowledge and analytical thinking
- **Time and resources**: Hunting is labor-intensive and can't be rushed
- **Management support**: Leadership must understand hunting may not immediately yield "wins"

Organizations lacking these prerequisites should focus on building fundamentals before launching hunting programs. (These considerations are explored in depth in Chapter 7: The Threat Hunting Maturity Model and Chapter 8: Organizational Readiness and Prerequisites.)