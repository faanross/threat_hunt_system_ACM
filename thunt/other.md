# Threat Hunting vs. Other Security Functions

## The Confusion Problem

When organizations first consider implementing threat hunting programs, one of the most common questions arises: "Isn't our SOC already doing this?" Or sometimes, "Why do we need threat hunting when we have an incident response team?" These questions reveal a fundamental confusion about how threat hunting relates to other security functions - a confusion that leads to misallocated resources, unrealistic expectations, and sometimes failed hunting programs.

The confusion is understandable. Modern security organizations have numerous teams with overlapping skills, similar tools, and related missions. SOC analysts, threat hunters, incident responders, penetration testers, and vulnerability managers all work with security data, understand attack techniques, and aim to improve the organization's security posture. But conflating these functions creates problems. You wouldn't expect your emergency room doctors to also perform preventive care and research - why would you expect your SOC analysts to simultaneously monitor alerts and proactively hunt for unknown threats?

This chapter clarifies the boundaries between threat hunting and related security functions, not to create organizational silos, but to help you understand what each function provides, how they complement each other, and why trying to have one team do everything often means nothing gets done well.


## Threat Hunting vs. SOC Operations

This is perhaps the most common source of confusion, and it's easy to see why. Both threat hunters and SOC analysts work with security data, investigate suspicious activity, and aim to detect threats. Both require technical skills, understanding of attack techniques, and access to similar tools. So what's the difference?

### The Fundamental Distinction: Alert-Driven vs. Hypothesis-Driven

SOC operations are fundamentally alert-driven. SOC analysts spend their time triaging and investigating alerts generated by security tools - SIEM correlation rules, EDR detections, IDS/IPS alerts, DLP violations, and dozens of other automated detection systems. When an alert fires, the analyst investigates: Is it a true positive or false positive? If true positive, how severe is it? What's the appropriate response?

This work is critical and challenging. A skilled SOC analyst must quickly assess alerts, determine their legitimacy, understand their context within the organization's environment, and make decisions about escalation or remediation. They're firefighters responding to smoke alarms - some are real fires requiring immediate action, many are false alarms requiring dismissal, and all must be triaged quickly to find the real threats.

Threat hunting, by contrast, is hypothesis-driven. Hunters don't wait for alerts. They start with a question or hypothesis - "I wonder if any of our domain controllers have been compromised with Golden Ticket attacks?" or "Are there any signs of data exfiltration through DNS tunneling?" - and then search through data to investigate. They're inspectors proactively checking the building for fire hazards before smoke alarms could even detect them.

### Different Workflows, Different Goals
#### SOC Analyst Workflow

```
┌──────────────────────────────┐
│     SOC ANALYST WORKFLOW     │
│     (Alert-Driven)           │
└──────────────────────────────┘

         ┌──────────┐
    ┌───▶│  Alert   │
    │    │  Fires   │
    │    └────┬─────┘
    │         │
    │         ▼
    │    ┌──────────────┐
    │    │   Analyst    │
    │    │ Investigates │
    │    └──────┬───────┘
    │           │
    │           ▼
    │    ┌─────────────────┐
    │    │   Determine:    │
    │    │ True or False   │
    │    │   Positive?     │
    │    └────┬───────┬────┘
    │         │       │
    │    False│       │True
    │         │       │
    │         │       ▼
    │         │  ┌──────────┐
    │         │  │ Escalate │
    │         │  │    or    │
    │         │  │Remediate │
    │         │  └────┬─────┘
    │         │       │
    │         └───┬───┘
    │             │
    │             ▼
    │        ┌──────────┐
    │        │ Document │
    │        │   and    │
    │        │  Close   │
    │        └────┬─────┘
    │             │
    └─────────────┘
          Next Alert in Queue

    Metrics: # of alerts processed, response time, accuracy
```


#### Threat Hunting Workflow

```
┌─────────────────────────────────────────────────────┐
│                THREAT HUNTER WORKFLOW               │
│                 (Hypothesis-Driven)                 │
└─────────────────────────────────────────────────────┘

                    ┌──────────────┐
           ┌─────┌─▶│  Generate    │
           │     │  │  Hypothesis  │               
           │     │  └──────┬───────┘               
           │     │         │                       
           │     │         ▼                       
           │     │  ┌──────────────┐               
           │     │─▶│     Plan     │               
           │     │  │Investigation │               
           │     │  └──────┬───────┘               
           │     │         │                       
           │     │         ▼                       
           │     │  ┌──────────────┐               
           │     │─▶│     Query    │              
           │     │  │  Data Sources│               
           │     │  └──────┬───────┘               
           │     │         │                       
           │     │         ▼                       
           │     │  ┌──────────────┐               
           │     │  │   Analyze    │               
           │     │  │   Results    │              
           │     │  └──────┬───────┘               
           │     │         │                       
           │     └─────◀───┤ Pivot                 
           │               │                       
           │               ▼                       
           │        ┌──────────────┐               
           │        │ Threat Found?│               
           │        └────┬────┬────┘               
           │             │    │                    
           │          No │    │ Yes                
           │             │    │                    
           │             │    ▼                    
           │             │ ┌──────────────┐        
           │             │ │    Alert     │        
           │             │ │   Response   │        
           │             │ │  Team/SOC    │        
           │             │ └──────┬───────┘        
           │             │        │                
           │             └────┬───┘                
           │                  │                    
           │                  ▼                    
           │           ┌──────────────┐            
           │           │   Document   │            
           │           │  Discoveries │            
           │           └──────┬───────┘            
           │                  │                    
           │                  ▼                   
           │           ┌──────────────┐           
           │           │ Create New   │           
           │           │  Detection   │           
           │           │    Rules     │           
           │           └──────┬───────┘           
           │                  │                  
           └──────────────────┘                   
                    New Insights                  
                                                  
                   

    Metrics: Threats discovered, detection coverage improved,
             reduced dwell time, new detections created
```


### Why You Need Both

Some organizations attempt to have SOC analysts "do hunting during slow periods." This rarely works well. Alert triage requires immediate response - you can't let alerts pile up while you investigate a hunting hypothesis. Hunting requires sustained focus and deep investigation - you can't effectively hunt in 15-minute increments between alerts.

More fundamentally, the skills and mindsets are different. Excellent SOC analysts develop pattern recognition for common alert types, efficiency in investigation workflows, and judgment about escalation. Excellent threat hunters develop creative hypothesis generation, comfort with ambiguity, and persistence in following weak signals. Some individuals excel at both, but they're different skill sets requiring different time allocations.

The two functions are complementary. SOC operations provide the baseline detection that handles known threats at scale. Threat hunting discovers gaps in that detection, finds threats that automated systems missed, and generates insights that improve SOC operations. When hunters find a new attack technique, they work with detection engineers to create SIEM rules - expanding what the SOC can detect automatically.


## Threat Hunting vs. Incident Response

Incident response (IR) and threat hunting also generate confusion because both involve investigating potential threats and both require deep technical skills. But the timing and trigger are completely different.

### When Each Function Activates

Incident response activates when a security incident has been confirmed or is highly suspected. Someone detected something - whether through SOC alerts, user reports, threat hunting, or external notification - and now the IR team takes over to contain, eradicate, and recover from the incident. IR is reactive by definition; you're responding to a known or strongly suspected threat.

Threat hunting occurs before an incident is confirmed. Hunters are proactively searching for threats that haven't yet been detected. They're working with suspicions, hypotheses, and weak signals rather than confirmed incidents. When hunters do find something, that's often when they hand off to incident response.

Think of it as a hand-off: threat hunting investigates until they either confirm a threat (hand off to IR) or validate that the hypothesis was incorrect (document and move to next hunt). Incident response picks up when a threat is confirmed and works through containment, eradication, and recovery.

### Different Objectives and Constraints

Incident response operates under significant time pressure. Once you've confirmed an active threat, speed matters tremendously. Every hour the adversary remains active, they could be stealing more data, compromising more systems, or entrenching their access. IR teams must move quickly but methodically through their response process.

Threat hunting typically operates without this acute time pressure. Yes, finding threats quickly is valuable, but hunters can spend days or weeks investigating a hypothesis. They're not racing against an active adversary conducting immediate harm - they're searching for adversaries who may have been present for months and might not even be active currently.

The scope differs as well. Incident response focuses narrowly on a specific incident: What's compromised? How did they get in? What did they do? How do we contain and remove them? Threat hunting has broader scope: Are there any signs of this technique anywhere in our environment? What about related techniques? What can we learn about our visibility gaps?


### The Critical Hand-Off

The most important interaction between hunting and IR is the hand-off when hunters discover actual threats. Mature organizations have clear processes for this transition. When a hunter finds evidence of compromise, they document their findings, preserve evidence, and escalate to the IR team. The IR team then follows established incident response procedures while the hunter moves on to other investigations.

This hand-off is crucial because the skills and mindsets required are different. Hunters excel at creative investigation and pattern recognition across large datasets. Incident responders excel at systematic containment, forensic analysis, and coordinated remediation. Trying to have the same person do both simultaneously often means neither is done optimally.

Some organizations create hybrid models where hunters and IR teams work closely during investigations, with hunters providing investigative insights and IR providing response coordination. This collaboration works well when roles and responsibilities are clearly defined.

## Threat Hunting vs. Vulnerability Management

This distinction is usually clearer, but confusion still arises, particularly around the question: "Should threat hunters be looking for vulnerabilities?"

### Fundamentally Different Questions

Vulnerability management asks: "What weaknesses exist in our systems that could be exploited?" It's focused on potential security issues - misconfigurations, unpatched software, weak controls, architectural flaws. Vulnerability management is preventive; it aims to fix weaknesses before adversaries exploit them.

Threat hunting asks: "Are adversaries currently exploiting our systems?" It's focused on actual malicious activity - active compromise, existing persistence mechanisms, ongoing data exfiltration. Hunting is detective; it aims to find adversaries who have already gotten in, whether through vulnerabilities or other means.

A vulnerability scan might reveal that a server is running an outdated version of SSH with known vulnerabilities. A threat hunt might investigate whether anyone has actually exploited those SSH vulnerabilities to compromise systems. These are related but distinct activities.


### Complementary Perspectives

While the core missions differ, hunting and vulnerability management inform each other. When threat hunters discover that adversaries exploited a particular vulnerability, vulnerability management teams can prioritize patching similar vulnerabilities elsewhere. When vulnerability assessments reveal critical weaknesses, hunters might investigate whether those weaknesses have already been exploited.

Some hunting hypotheses explicitly focus on exploitation of vulnerabilities: "I know we have systems with ProxyLogon vulnerabilities - have any of them been exploited?" But this is still hunting (looking for active exploitation) rather than vulnerability management (identifying and patching vulnerable systems).

Organizations sometimes try to have vulnerability management teams also do threat hunting, or vice versa. This rarely works well because the skill sets are quite different. Vulnerability management requires systematic asset inventory, understanding of technical security controls, familiarity with patching and configuration management processes. Threat hunting requires log analysis, understanding of adversary behaviour, and investigative thinking. While some overlap exists, they're distinct specializations.

## Threat Hunting vs. Penetration Testing and Red Teaming

These offensive security functions also generate confusion, particularly since both hunters and penetration testers need to understand attack techniques. But the fundamental orientation is opposite.

### Offensive vs. Defensive

Penetration testing and red teaming are offensive activities. Penetration testers actively attempt to compromise systems, typically within defined scope and rules of engagement. They're simulating adversaries to test defenses. Red teams conduct more realistic, sustained campaigns to test detection and response capabilities across multiple security layers.

Threat hunting is defensive. Hunters aren't trying to break in - they're trying to find adversaries who already have. They're not simulating attacks - they're detecting real ones (or validating that none exist).

The skills involved overlap significantly. Both hunters and pentesters need to understand how attacks work, what tools adversaries use, how to evade detection, and what evidence attacks leave behind. But they apply these skills from opposite perspectives. Pentesters ask "How would I break in?" while hunters ask "If someone broke in this way, what evidence would they leave?"

### The Purple Team Bridge

"Purple teaming" has emerged as a practice that bridges offensive and defensive activities. In purple team exercises, red teamers conduct attacks while blue team defenders (including hunters) attempt to detect and respond, with both sides collaborating to improve defenses.

These exercises provide excellent opportunities for threat hunters. Red team attacks that evade detection reveal gaps in hunting coverage and generate hypotheses for future hunts. Hunters can request that red teams execute specific techniques to test detection capabilities. The collaboration improves both offensive and defensive capabilities.

Some organizations rotate security staff between offensive and defensive roles, and this can work well. Understanding offense deeply improves defensive thinking, and vice versa. But during any given work period, these remain distinct functions with different operational goals.


## Threat Hunting vs. Threat Intelligence

Threat intelligence and threat hunting are closely related but distinct functions that work together synergistically.

### Intelligence Informs Hunting, Hunting Generates Intelligence

Threat intelligence involves collecting, analyzing, and disseminating information about threats, adversaries, and attack techniques. Intelligence analysts track threat actor groups, document their tactics and tools, analyze malware, and produce reports that help organizations understand the threat landscape.

Threat hunting uses this intelligence operationally. When threat intelligence reports that APT29 is targeting organizations in your sector with specific techniques, hunters can search for evidence of those techniques in your environment. Intelligence provides context, priorities, and hypotheses that guide hunting activities.

Conversely, hunting generates intelligence. When hunters discover new attack techniques, novel malware, or previously unknown adversary behaviors, this becomes intelligence that can be shared (appropriately sanitized) with the broader community. Hunting validates threat intelligence - proving that theoretical techniques are actually being used - and provides ground truth about what threats are active in real environments.

### Different Operational Focus

Threat intelligence analysts spend their time researching threats, analyzing malware, monitoring adversary infrastructure, and producing reports. They're typically working with external data - malware samples, indicator feeds, dark web monitoring, industry reports.

Threat hunters spend their time searching through internal data - endpoint logs, network traffic, authentication events - looking for evidence of compromise. They're operationally focused on their specific environment rather than producing generalized intelligence.

Many organizations struggle to effectively operationalize threat intelligence. They subscribe to threat feeds but don't have processes to actually use the intelligence for hunting or detection improvement. The most mature organizations create tight integration: intelligence analysts regularly brief hunters on relevant threats, hunters actively search for those threats in the environment, and findings flow back to intelligence teams to improve future collection and analysis.



## Threat Hunting vs. Security Architecture

Security architecture is a strategic function focused on designing security controls, systems, and processes. Architects make decisions about which security tools to deploy, how networks should be segmented, what authentication mechanisms to use, and how to integrate security into development and operations.

Threat hunting is an operational function that works within the constraints of existing architecture. Hunters use the tools and data sources that architects have provided, operating within the architectural decisions that have been made.

However, hunting provides critical feedback to architecture. When hunters discover that they lack visibility into certain attack vectors, this informs architectural decisions about what logging to enable or what tools to deploy. When hunters find that network segmentation failures allowed lateral movement, this drives architectural improvements. When hunters struggle to correlate events across disconnected security tools, this highlights integration gaps that architecture should address.

The relationship should be collaborative. Architects should consult hunters about what visibility and capabilities they need to be effective. Hunters should provide regular feedback about architectural gaps and limitations they encounter. Some of the best security architectures emerge from this tight feedback loop between strategic design and operational reality.

## The Complementary Security Ecosystem

After reading all these distinctions, you might worry about creating organizational silos or rigid boundaries between functions. That's not the goal. The most effective security organizations recognize these functions as complementary parts of an integrated whole.

Think of it like a hospital: emergency medicine, preventive care, surgery, and diagnostics are distinct specializations requiring different skills and approaches. But they all work together to achieve the overarching goal of patient health. Patients benefit from having specialists in each area rather than generalists trying to do everything.

Similarly, your security program benefits from having:

- **SOC operations** handling high-volume alert triage and known threat detection
- **Threat hunting** proactively searching for unknown threats and detection gaps
- **Incident response** containing and remediating confirmed incidents
- **Vulnerability management** identifying and fixing security weaknesses
- **Penetration testing** simulating attacks to test defenses
- **Threat intelligence** providing context about adversaries and techniques
- **Security architecture** designing the overall security ecosystem

Each function has distinct value, and trying to have one team do everything usually means nothing is done excellently. But these functions must coordinate closely, share information freely, and support each other's missions.

## Common Pitfalls and Misallocations

Understanding these distinctions helps avoid common organizational mistakes:

**Pitfall 1: Expecting SOC to "do hunting during downtime"** SOC alert loads rarely have sustained downtime, and hunting requires focused investigation time. This expectation typically results in neither alert triage nor hunting being done well.

**Pitfall 2: Assuming hunting eliminates the need for SOC** Hunting is too slow and labor-intensive to replace high-volume alert triage. You need both automated detection (via SOC) and proactive hunting.

**Pitfall 3: Using penetration testing as validation that hunting isn't needed** "Our pentest came back clean, so we don't need hunting" misunderstands what each provides. Pentests simulate attacks; hunting finds real adversaries who may use different techniques.

**Pitfall 4: Starting hunting before SOC fundamentals are solid** If your SOC can't handle basic alert triage effectively, adding hunting won't help. Build foundational capabilities first.

**Pitfall 5: Expecting hunters to also do incident response** While some overlap in skills exists, the different timing and constraints mean trying to do both simultaneously usually means neither is done optimally.

**Pitfall 6: Measuring hunting success by "incidents found"** This misunderstands hunting's value. Null results that validate defenses, improved detection coverage, and environmental learning are all valuable outcomes, even when no active threats are found.





